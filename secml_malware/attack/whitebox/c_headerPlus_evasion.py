import struct
import numpy as np
import torch
import lief
from secml.settings import SECML_PYTORCH_USE_CUDA
from secml_malware.utils.pe_operations import create_int_list_from_x_adv
from secml_malware.attack.whitebox.c_fast_gradient_sign_evasion import CFastGradientSignMethodEvasion
from secml_malware.attack.whitebox.c_discretized_bytes_evasion import CDiscreteBytesEvasion
from secml_malware.models import CClassifierEnd2EndMalware

use_cuda = torch.cuda.is_available() and SECML_PYTORCH_USE_CUDA


class CHeaderPlusEvasion(CDiscreteBytesEvasion):
	"""Creates the attack that perturbs the header of a Windows PE malware.
	"""

	def __init__(
			self,
			end2end_model: CDiscreteBytesEvasion,
			index_to_perturb: list = None,
			iterations: int = 100,
			is_debug: bool = False,
			random_init: bool = False,
			saliency_select: bool = True,
			threshold: float = 0,
			penalty_regularizer: int = 0,
			how_many_padding_bytes: int = 144,
			how_many_change_bytes: int = 58,
			compute_slack: bool = True,
			saliency: list = None
	):
		"""
		Creates the evasion object

		Parameters
		----------
		end2end_model : CClassifierEnd2EndMalware
			the target end-to-end model
		index_to_perturb : list
			a list containing the index to perturb inside the samples
		iterations : int, optional, default 100
			the number of iterations of the optimizer
		is_debug : bool, optional, default False
			if True, prints debug information during the optimization
		random_init : bool, optional, default False
			if True, it randomizes the locations set by index_to_perturb before starting the optimization
		optimize_all_dos : bool, optional, default False
			if True, set as editable all the DOS header, not only the specified portion
		threshold : float, optional, default 0
			the detection threshold to bypass. Default is 0
		penalty_regularizer : float
			the reularization parameter, Default is 0
		how_many : int
			how many padding byte to inject, Default is 144
		"""

		super(CHeaderPlusEvasion, self).__init__(
			end2end_model,
			index_to_perturb,
			iterations,
			is_debug,
			random_init,
			threshold,
			penalty_regularizer,
		)
		self.how_many_padding_bytes = how_many_padding_bytes
		self.how_many_change_bytes = how_many_change_bytes
		self.compute_slack = compute_slack
		self.saliency_select = saliency_select
		self.saliency = saliency
		self.indexes_to_perturb = []
	def _set_dos_indexes(self, x0):

		header = [i for i in range(2, 0x3C)]
		padding = self._create_pading_indexes(x0)

		slacks = self._create_slack_indexes(x0)
		slack_all = []
		if self.compute_slack:
			for s in range(len(slacks)):
				if slacks[s]:
					slack_all.extend(slacks[s])

		indexes = header + slack_all + padding if self.compute_slack else header + padding

		if self.saliency_select == True:
			'''
			################# select max byte #################
			mask = np.zeros((self.max_input_length,))
			for i in indexes:
				mask[i] = 1
			saliency = self.saliency * mask
			idx_select = saliency.argsort()[-self.how_many_change_bytes:]
			idx_select.sort()
			self.indexes_to_perturb = idx_select.tolist()
			'''
			'''
			################ select slack with max average saliency #################
			saliency_header = sum(self.saliency[header[0]:header[-1]])/len(header)
			saliency_padding = sum(self.saliency[padding[0]:padding[-1]])/len(padding) if len(padding) != 0 else 0
			saliency_sections = np.zeros((len(slacks)), dtype=np.float64)
			for i, section in enumerate(slacks):
				saliency_sections[i] = sum(self.saliency[section[0]:section[-1]])/len(section) if section is not None else -1000

			score_all = np.insert(saliency_sections, 0, saliency_padding)

			score_all = np.insert(score_all, 0, saliency_header)

			num_modify = 0
			while num_modify < self.how_many_change_bytes:
				idx = np.argmax(score_all)
				score_all[idx] = -1000
				if idx == 0: # select header
					self.indexes_to_perturb.extend(header)
				elif idx == 1: # select padding
					self.indexes_to_perturb.extend(padding)
				else: # select section slack
					self.indexes_to_perturb.extend(slacks[idx-2])

				num_modify = len(self.indexes_to_perturb)

			self.indexes_to_perturb = self.indexes_to_perturb[:self.how_many_change_bytes]
			'''
			################  select section with max total saliency  #################
			dos_header = []
			pe_header = []

			x_bytes = create_int_list_from_x_adv(x0, self.classifier.get_embedding_value(),
												 self.classifier.get_is_shifting_values())
			liefpe = lief.PE.parse(x_bytes)
			pe_position = liefpe.dos_header.addressof_new_exeheader
			optional_header_size = liefpe.header.sizeof_optional_header
			pe_header.extend(list(range(pe_position, pe_position + optional_header_size)))
			dos_header.extend(list(range(0, pe_position)))
			sections = [[] for i in range(len(liefpe.sections))]
			section_name = []
			idx_s = 0
			for s in liefpe.sections:
				sections[idx_s].extend(list(range(s.offset, s.offset + s.size)))
				section_name.append(s.name)
				idx_s += 1

			score = sum(self.saliency)
			dos_score = sum(self.saliency[byte] for byte in dos_header) / len(dos_header)
			pe_score = sum(self.saliency[byte] for byte in pe_header) / len(pe_header)
			padding_score = sum(self.saliency[padding[0]:padding[-1]])/ len(padding) if len(padding) != 0 else 0
			se_score = np.zeros((len(liefpe.sections)))
			for s in range(len(liefpe.sections)):
				se_score[s] = sum(self.saliency[byte] for byte in sections[s]) / len(sections)

			score_all = np.insert(se_score, 0, padding_score)
			score_all = np.insert(score_all, 0, dos_score + pe_score)
			
			num_modify = 0
			while num_modify < self.how_many_change_bytes:
				idx = np.argmax(score_all)
				score_all[idx] = -1000
				if idx == 0: # select header
					self.indexes_to_perturb.extend(header)
				elif idx == 1: # select padding
					self.indexes_to_perturb.extend(padding)
				else: # select section slack
					if slacks[idx-2] is not None:
						self.indexes_to_perturb.extend(slacks[idx-2])

				num_modify = len(self.indexes_to_perturb)

			self.indexes_to_perturb = self.indexes_to_perturb[:self.how_many_change_bytes]


		else:
			self.indexes_to_perturb = indexes[:self.how_many_change_bytes]

		self._how_many = len(self.indexes_to_perturb)
		if self.is_debug:
			print(f"perturbing {self._how_many}")


	def _create_slack_indexes(self, x0):
		x_bytes = create_int_list_from_x_adv(x0, self.classifier.get_embedding_value(),
											 self.classifier.get_is_shifting_values())
		try:
			liefpe = lief.PE.parse(x_bytes)
		except:
			return []
		window_input_length = self.classifier.get_input_max_length()
		all_slack_space = [[] for _ in range(len(liefpe.sections))]
		for i, s in enumerate(liefpe.sections):
			if s.size > s.virtual_size:
				all_slack_space[i].extend(list(range(min(window_input_length, s.offset + s.virtual_size),
												  min(window_input_length, s.offset + s.size))))
			else:
				all_slack_space[i] = None
		return all_slack_space

	def _create_pading_indexes(self, x0):
		invalid_value = 256 if self.invalid_pos == -1 else self.invalid_pos
		padding_positions = x0.find(x0 == invalid_value)
		if not padding_positions:
			return []
		else:
			return list(
				range(
					padding_positions[0],
					min(x0.size, padding_positions[0] + self.how_many_padding_bytes),
				)
			)


	def _run(self, x0, y0, x_init=None):
		self._set_dos_indexes(x0)

		return super(CHeaderPlusEvasion, self)._run(x0, y0, x_init)
